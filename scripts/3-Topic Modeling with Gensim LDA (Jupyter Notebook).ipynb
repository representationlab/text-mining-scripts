{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling with Gensim LDA\n",
    "This code replicates the Google Colab topic modeling notebook for use on Jupyter Notebook or another local Python environment.\n",
    "\n",
    "Below, Gensim is used to create LDA topic models of a pre-loaded dataframe of texts. Methods for evaluating topic coherence and analyzing topic output are also demonstrated. \n",
    "\n",
    "LDA topic modeling is based on the assumption that documents are a mixture of topics (# topics is set by the researcher) and that topics are a mixture of words. To determine which words belong to each topic, the LDA model randomly assigns each word in a set of documents to a topic, then iterates through the assignments and makes adjustments until all words are assigned to the topics where they have the highest probability of belonging. \n",
    "\n",
    "This code is adapted from [Intro to Topic Modeling with Gensim and pyLDAvis](https://github.com/hawc2/text-analysis-with-python/blob/master/Topic_Modeling.ipynb).\n",
    "\n",
    "LDA topic modeling can be used with aggregated or disaggregated data.\n",
    "It works well with disaggregated texts from the Text Sectioning and Disaggregation code from [this repository](https://github.com/SF-Nexus/Extracted-Features).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and Load Packages\n",
    "This code requires three main packages:\n",
    "- **NLTK:** Cleaning disaggregated data\n",
    "- **Gensim:** Preprocessing data and creating word embeddings, coherence models and topic models\n",
    "- **LDAvis:** Visualizing topic models\n",
    "\n",
    "Several other packages for wrangling and processing the data, such as io and pandas, will also be installed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BEFORE USING THIS CODE FOR THE FIRST TIME**:\n",
    "\n",
    "This code was created using a Jupyter Notebook through Anaconda. Before running the code for the first time, **create a new environment in Anaconda** where all packages and libraries will be stored for future usages. Learn how to create an environment using Anaconda Navigator [here.](https://wiki.math.ntnu.no/anaconda/createenvironment)\n",
    "\n",
    "When using a new environment for the first time, several packages will need to be installed. It is recommended that you install these directly in the terminal rather than through Jupyter Notebook (though both are possible). To install in terminal, open a new terminal window, make sure you are in the correct environment, and input the following commands: \n",
    "\n",
    "```conda install nltk```\n",
    "```conda install gensim```\n",
    "```conda install pyLDAvis```\n",
    "\n",
    "Once these packages are installed, they can be imported below. *You only need to install these the FIRST time you are using this code in a new environment.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "#Get dictionary of English words to keep \n",
    "from nltk.corpus import words\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')\n",
    "from nltk import WordNetLemmatizer\n",
    "!pip install wordcloud\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import multiprocessing\n",
    "!pip install pyLDAvis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve and Convert Corpus to Data Frame\n",
    "\n",
    "This code requires the upload of a previously created dataframe which contains a corpus of disaggregated texts. For optimal use, this dataframe should also contain labels associated with each text (e.g. book or chapter numbers). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Get current working directory \n",
    "path = os.getcwd()\n",
    "print(path)\n",
    "\n",
    "#Change working directory\n",
    "path = os.chdir(\"/home/dssadmin/Desktop/\")\n",
    "\n",
    "#Upload dataframeâˆš\n",
    "#df = pd.read_csv('mellon_text_ebook_chunks.csv')\n",
    "df = pd.read_csv('mellon_txt_chunks_clean.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add values in text column of choice to new list \n",
    "data = df.Text.values.tolist()\n",
    "\n",
    "#Define function to perform simple preprocessing on text\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "      yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "#Run preprocessing on data list\n",
    "data_words = list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Dictionary and Corpus\n",
    "Once the dataset is cleaned, two inputs must be created to run the topic model. Creating the dictionary maps every word in the corpus with a unique id number. The variable corpus is calculated by determining the frequency of each word in the document. Another optional cleaning measure can be used here--removing words that are extremely rare (existing in < n number of texts) or common (existing in > n number of texts).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import dictionary\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(data_words)\n",
    "\n",
    "#Calculate term document frequency for each word in dataset\n",
    "corpus = [dictionary.doc2bow(doc) for doc in data_words]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL cleaning: filter out words that occur less than 20 documents, or more than 80% of the documents.\n",
    "#dictionary.filter_extremes(no_below=2, no_above=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get number of unique tokens and documents\n",
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multicore Processing (Use this One)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up runtime, use the LdaMulticore model option and set number of workers to the number of your machine's cores minus one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test LDA model multicore\n",
    "from gensim.models import ldamulticore\n",
    "from gensim import corpora, models\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 100\n",
    "chunksize = 1000\n",
    "passes = 400\n",
    "iterations = 2000\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "\n",
    "# Make an index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "lda_model2 = models.LdaMulticore(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    workers = cores-1,\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=1\n",
    ")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model2.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute C_V Coherence Score\n",
    "coherence_model_lda2 = CoherenceModel(model=lda_model2, texts=data_words, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda2.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Topic Model Output\n",
    "Once the model has been run, it is possible to retrieve the top words in each topic and visualing the model. These are methods can help further assess model coherence and point to future directions for analysis:\n",
    "- **Top Words Per Topic:** Evaluate to what extent each topic contains semantically similar words, how/why these words might be meaningful in context of corpus\n",
    "- **Visualizations:** Determine topic relatedness (how far apart topic circles are on plane) and topic prevalence (how large circles are corresponds to topic prevaence in corpus)\n",
    "\n",
    "Additional reading: \n",
    "\n",
    "https://towardsdatascience.com/6-tips-to-optimize-an-nlp-topic-model-for-interpretability-20742f3047e2\n",
    "\n",
    "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#15visualizethetopicskeywords\n",
    "\n",
    "https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Print n number of words in each topic\n",
    "for idx, topic in lda_model2.print_topics(num_words=20):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionary with topics and words\n",
    "my_dict = {\"Topic\":[],\"Words\":[]}\n",
    "for idx, topic in lda_model2.print_topics(num_words=20):\n",
    "    my_dict[\"Topic\"].append(idx)\n",
    "    my_dict[\"Words\"].append(topic)\n",
    "\n",
    "#Convert dictionary to dataframe\n",
    "topics_df = pd.DataFrame.from_dict(my_dict)\n",
    "topics_df.head()\n",
    "\n",
    "#Change path to where you want to save the files\n",
    "path = os.chdir(\"/home/dssadmin/Desktop/\")\n",
    "\n",
    "#Download dataframe as csv\n",
    "topics_df.to_csv('LDA_topic_word_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove custom words (stopwords and names not previously filtered out)\n",
    "#custom_stop_words = ['wa']\n",
    "\n",
    "#Define word cloud function\n",
    "from wordcloud import WordCloud \n",
    "def create_wordcloud(model, topic):\n",
    "    text = {word: value for word, value in model.show_topic(topic) if word not in custom_stop_words}\n",
    "    wc = WordCloud(background_color=\"white\", max_words=1000)\n",
    "    wc.generate_from_frequencies(text)\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Topic\" + \" \"+ str(topic))\n",
    "    plt.show()\n",
    "    \n",
    "#Ignore depreciation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Create word clouds\n",
    "for i in range(1,num_topics):\n",
    "    create_wordcloud(lda_model2, topic=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create visualization of topic model above \n",
    "%matplotlib inline\n",
    "import pyLDAvis.gensim_models\n",
    "vis = pyLDAvis.gensim_models.prepare(topic_model=lda_model2, corpus=corpus, dictionary=dictionary, mds='mmds')\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(vis, 'Mellon200_multicore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Top Topics Per Document\n",
    "\n",
    "Find the topic with highest percentage in each document in corpus. \n",
    "\n",
    "Additional reading: \n",
    "https://towardsdatascience.com/topic-modelling-in-python-with-spacy-and-gensim-dc8f7748bdbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function that retrieves dominant topic for each document and puts in dataframe\n",
    "def format_topics_texts(ldamodel=None, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    text_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                text_topics_df = text_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    text_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    text_topics_df = pd.concat([text_topics_df, contents], axis=1)\n",
    "    return(text_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run dominant topic function on corpus\n",
    "df_topic_texts_keywords = format_topics_texts(ldamodel=lda_model2, corpus=corpus, texts=data_words)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_texts_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dominant_topic['Title'] = df['Book + Chunk']\n",
    "df_dominant_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download top topic per document df to csv\n",
    "df_dominant_topic.to_csv('LDA_df_dominant_topic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get DataFrame with Each Topic and Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only topic and keyword columns\n",
    "topics_keywords_df = df_dominant_topic[['Dominant_Topic', 'Keywords']].copy()\n",
    "\n",
    "#Remove duplicates\n",
    "topics_keywords_df = topics_keywords_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset index and sort topics in ascending order\n",
    "topics_keywords_df = topics_keywords_df.reset_index(drop=True)\n",
    "topics_keywords_df = topics_keywords_df.sort_values(by='Dominant_Topic') \n",
    "topics_keywords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download to csv\n",
    "topics_keywords_df.to_csv('LDA_topics_keywords_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Top Documents Per Topic\n",
    "Calculate the top documents attributed to each topic in the model. \n",
    "\n",
    "Additional reading:\n",
    "\n",
    "https://stackoverflow.com/questions/63777101/topic-wise-document-distribution-in-gensim-lda\n",
    "\n",
    "https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/topic_methods.ipynb \n",
    "\n",
    "https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/#7.-The-most-representative-sentence-for-each-topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Book + Chapter labels to dataframe for easier ID\n",
    "doc_names = df['Book + Chunk']\n",
    "df_topic_texts_keywords = df_topic_texts_keywords.join(doc_names)\n",
    "df_topic_texts_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get most representative text for each topic \n",
    "#Display setting to show more characters in column\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "#Create new dataframe and group topic keywords by dominant topic column\n",
    "topics_sorted_df = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = df_topic_texts_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "#Sort data by percent contribution and select highest n values for each topic\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    topics_sorted_df = pd.concat([topics_sorted_df, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], \n",
    "                                            axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Index of new df\n",
    "topics_sorted_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "topics_sorted_df.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\", \"Text Name\"]\n",
    "topics_sorted_df = topics_sorted_df.reindex(columns=['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text Name\", \"Representative Text\"])\n",
    "# Show\n",
    "topics_sorted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download top doc per topic to dataframe\n",
    "topics_sorted_df.to_csv('top_doc_per_LDA_topic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "**More Examples of Topic Modeling Research:**\n",
    "\n",
    "*   http://www.digitalhumanities.org/dhq/vol/11/2/000291/000291.html\n",
    "*   http://www.cs.columbia.edu/~blei/papers/Blei2011.pdf\n",
    "*   https://maria-antoniak.github.io/resources/2019_cscw_birth_stories.pdf \n",
    "\n",
    "**More Topic Modeling Tools:**\n",
    "\n",
    "*   https://github.com/polsci/colab-gensim-mallet/blob/master/topic-modeling-with-colab-gensim-mallet.ipynb\n",
    "*   https://github.com/laurejt/authorless-tms \n",
    "*   https://colab.research.google.com/github/kldarek/skok/blob/master/_notebooks/2021-05-27-Topic-Models-Introduction.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore the rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONAL STEP - Find Optimal Number of Topics\n",
    "\n",
    "Calculating topic model coherence (i.e. similarity between the highest-scoring words in each topic) is one way to assess the optimal number of topics to use when creating and visualizing topic models. Below are two methods of calculating coherence: **C_V coherence**, which is calculated based on word co-occurences, and **U_Mass coherence**, which is calculated based on how frequently documents containing high-scoring words co-occur in the corpus. Both have been used in prior research and either may yield better results, depending on corpus specifications.\n",
    "\n",
    "Additional readings: \n",
    "\n",
    "https://aclanthology.org/D12-1087.pdf \n",
    "\n",
    "https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0\n",
    "\n",
    "https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C_V Coherence Calculations\n",
    "\n",
    "The function below calculates C_V coherence scores for n topic models run based on set parameters. Coherence is calculated on a range of 0 < x < 1 where higher-scoring models are assumed more coherent. For example, a model with a score of .50 is more coherent than a model with a .25 score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "from gensim.models import ldamulticore\n",
    "from gensim import corpora, models\n",
    "    \n",
    "#Define list for model and coherence values\n",
    "coherence = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#Find coherence for set range of models and append to list\n",
    "for k in tqdm(range(2,200)):\n",
    "    #print('Round: '+str(k))\n",
    "    ldamodel = models.LdaMulticore(corpus, num_topics=k, \\\n",
    "               id2word = dictionary, workers = cores-1, eval_every = None)\n",
    "    cm = gensim.models.coherencemodel.CoherenceModel(\\\n",
    "         model=ldamodel, texts=data_words,\\\n",
    "         dictionary=dictionary, coherence='c_v')   \n",
    "                                                \n",
    "    coherence.append((k,cm.get_coherence()))\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose coherence data\n",
    "x, y = np.array(coherence).T\n",
    "  \n",
    "      \n",
    "# plot our list in X,Y coordinates\n",
    "optimal, = plt.plot(x, y)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get coherence score for each num topics sorted from highest to lowest\n",
    "#Highest value will be optimal number of topics\n",
    "Data = {'Num Topics': optimal.get_xdata(), 'Coherence': optimal.get_ydata()}\n",
    "type(Data)\n",
    "df_optimal = pd.DataFrame.from_dict(Data)\n",
    "df_optimal.sort_values(by='Coherence',ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U_Mass Coherence Calculation\n",
    "The function below calculates U_Mass coherence scores of n topic models run based on set parameters. Coherence is calculated on a range of -14 < x < 14 where lower-scoring models are more coherent. For example, a model with a score of -.4 is less coherent than a model with a -.9 score. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define list for model and coherence values\n",
    "coherence2 = []\n",
    "\n",
    "#Find coherence for set range of models and append to list\n",
    "for k in range(2,200):\n",
    "    print('Round: '+str(k))\n",
    "    Lda = gensim.models.ldamodel.LdaModel\n",
    "    ldamodel = Lda(corpus, num_topics=k, \\\n",
    "               id2word = dictionary, eval_every = None)\n",
    "    \n",
    "    cm = gensim.models.coherencemodel.CoherenceModel(\\\n",
    "         model=ldamodel, texts=data_words,\\\n",
    "         dictionary=dictionary, coherence='u_mass')   \n",
    "                                                \n",
    "    coherence2.append((k,cm.get_coherence()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose coherence data\n",
    "x, y = np.array(coherence2).T\n",
    "        \n",
    "# plot our list in X,Y coordinates\n",
    "optimal2, = plt.plot(x, y)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get coherence score for each num topics sorted from highest to lowest\n",
    "#Lowest value will be optimal number of topics\n",
    "Data = {'Num Topics': optimal2.get_xdata(), 'Coherence': optimal2.get_ydata()}\n",
    "type(Data)\n",
    "df_optimal2 = pd.DataFrame.from_dict(Data)\n",
    "df_optimal2.sort_values(by='Coherence',ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Topic Models with Optimal Parameters (Skip Down to Multicore option)\n",
    "Input the parameters of the topic model and run. The model has multiple parameters, including: \n",
    "- num_topics: Number of topics the model will generate (default = 100)\n",
    "- chunksize: Number of documents processed at a time (default = 2000)\n",
    "- passes: Number of times model is trained on corpus (default = 1)\n",
    "- iterations: Number of times model \"loops\" over each document (default = 50)\n",
    "\n",
    "Calculating coherence (above) helps determine topic number, and other methods can be used to determine appropriate values for the other parameters. \n",
    "\n",
    "**Chunk size:** Setting chunk size to a larger number than that of documents in the model ensures that all documents are processed at once (though this requires enough memory space). \n",
    "\n",
    "**Passes and Iterations:** A common way to determine the best number of passes and iterations is by training a topic model and checking the \"log\" to see the document convergence rate (what percentage of topic/word assignments attain stability). If convergence is low, increase number of passes and interations. \n",
    "\n",
    "In general, as chunksize increases, passes and iterations should increase as well. Also keep in mind that corpus size may effect number of topics--in the cases of smaller corpora, using too many topics will likely make them too general OR too limited to the context of only one text. Consider running multiple models and comparing coherence, perplexity, and top words per topic. \n",
    "\n",
    "Additional reading: \n",
    "\n",
    "https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html\n",
    "\n",
    "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#12buildingthetopicmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import logging to gauge passes and iterations; will output file to working directory\n",
    "import logging\n",
    "logging.basicConfig(filename='gensim.log',\n",
    "                    format=\"%(asctime)s:%(levelname)s:%(message)s\",\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model.\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 100\n",
    "chunksize = 1000\n",
    "passes = 20\n",
    "iterations = 40\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make an index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "lda_model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=1\n",
    ")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute C_V Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_words, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
